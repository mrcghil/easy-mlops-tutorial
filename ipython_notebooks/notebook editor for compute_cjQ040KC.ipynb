{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-meg_clip_dev",
      "display_name": "Python (env meg_clip_dev)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "mghilar",
    "associatedRecipe": "compute_cjQ040KC",
    "createdOn": 1710267448499,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "creator": "mghilar"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom matplotlib import pyplot as plt\nfrom dataiku import pandasutils as pdu"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\ncollected_data \u003d dataiku.Dataset(\"collected_data\")\ncollected_data_df \u003d collected_data.get_dataframe()\n\nmodel_versions \u003d dataiku.Folder(\"cjQ040KC\")\nmodel_versions_info \u003d model_versions.get_info()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Problem constants\nALL_IN_COST \u003d 1\nINITIAL_PRICE \u003d 1.8\n\ndef income_function_single(price_delta:np.ndarray) -\u003e np.ndarray:\n    return (INITIAL_PRICE + price_delta) - ALL_IN_COST"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Where to save successive modelling tests\nclass ModelParameters:\n    \n    def __init__(self, hypers, parameters, outputs, scores):\n        # Hyperparams\n        self.hypers \u003d hypers\n        # Relevant paramters\n        self.parameters \u003d parameters\n        # outputs\n        self.outputs \u003d outputs\n        # self score\n        self.scores \u003d scores\n    \n    def to_json(self):\n        return json.dumps({\n            \"hypers\": self.hyper,\n            \"parameters\": self.parameters,\n            \"outputs\": self.outputs,\n            \"scores\":self.scores\n        })"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check the performance of the live model to see how we are performing\nlive_df \u003d collected_data_df[collected_data_df[\u0027source\u0027] \u003d\u003d \"live\"].reset_index()\n\n# If the performance is good we can skip the model creation below\nif False:\n    # Model \n    REFIT_MODEL \u003d True\nelse:\n    REFIT_MODEL \u003d False"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We want to find the product discount that maximises our expected income\n\n## This will contain all the produced models\nmodels_collection \u003d []\n\n## Iterate for all the model builds (data included)\nfor index in range(1): \n    print(f\"Running tuning: {index+1} ...\")\n    \n    ## Can select the data better (perform split and ...)\n    X \u003d collected_data_df[\u0027price_delta\u0027].values.reshape(-1, 1)\n    Y \u003d collected_data_df[\u0027output\u0027].values\n\n    ## 1D Logistic regression\n    ## We model first the relationship between outcome (transaction occurred) and price\n    purchase_classifier \u003d LogisticRegression(\n        random_state\u003dNone,\n        # solver\u003d\u0027lbfgs\u0027,\n        # penalty\u003d\u0027l2\u0027\n        # max_iter\u003d100,\n    ).fit(\n        X,\n        Y,\n    )\n    \n    ## This is the simplest thing not the best\n    simple_fit_score \u003d purchase_classifier.score(X,Y)\n    \n    ## Calculate the optimal price for the period\n    nodes \u003d np.linspace(-1,1,1001)\n    ### Probability of purchase\n    purchase_prob \u003d purchase_classifier.predict_proba(nodes.reshape(-1, 1))[:,1]\n    purchase_pdf \u003d purchase_prob / np.trapz(purchase_prob, nodes)\n    ### Incomes\n    income_line \u003d income_function_single(nodes)\n    \n    optimal_price_delta_ind \u003d np.argmax(income_line * purchase_pdf)\n    optimal_price_delta \u003d nodes[optimal_price_delta_ind]\n    print(f\"Optimal price delta at {optimal_price_delta} ...\")\n    \n    plt.plot(nodes, income_line)\n    plt.plot(nodes, purchase_pdf)\n    plt.plot(nodes, income_line * purchase_pdf)\n    plt.show()\n    \n    models_collection.append(\n        ModelParameters(\n            {},\n            {},\n            {\n                \"action\": optimal_price_delta\n            },\n            {\n                \"score\": simple_fit_score\n            }\n        )\n    )\n    \n    \n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\nfor ind, model in enumerate(models_collection):\n    with model_versions.get_writer(os.path.join(current_time.strftime(\"%Y%m%d_%H_%M_%S\"), \"_\".join([\"model\", f\"{ind}.json\"]))) as w:\n        w.write(\n            model.to_csv().encode()\n        )"
      ],
      "outputs": []
    }
  ]
}