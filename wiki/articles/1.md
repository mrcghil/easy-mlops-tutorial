## Basic Tuning Strategies

### Manual

Up to the Data Scientist to define the parameters to modify.

### Grid Search

We go through a predetermined set of hyperparamters and pick the best combination.

- Quite slow
- Dimensionality curse
- Fits all combinations specified

### Random Search

Unlike grid search, a random search is not deterministic. This means that the parameters to try are sampled from a distribution. 

- Many algorithms build on top of this (simulated annealing)
- Can be improved if we pass in distributions

## More Advanced Strategies

### Model-based Search

We can create a meta-problem where we look for the optimal performance over the test set and determine the hyperparameters by using gradient-based approaches.

